import os
import csv
import re
import sys
from bs4 import BeautifulSoup, NavigableString

# General file info:
#   Tab size: 4 spaces.
#   Generated by LLM, verified and reworked by project maintainers.


def format_node(node):
	"""
	Recursively converts HTML nodes to a simplified man-page text format.
	- Lists: '- ' at the start of a line.
	- Links: {{text}} for now.
	- Bold/Italic/Underline: {{text}}.
	"""
	if isinstance(node, NavigableString):
		return str(node)
	
	tag = node.name
	content = "".join(format_node(child) for child in node.children)
	
	if tag in ['b', 'u', 'i']:
		return "{{" + content + "}}"
	if tag == 'a':
		return "{{" + content + "}}"
	if tag == 'li':
		return "- " + content.strip()
	if tag == 'ul':
		return content
	if tag == 'dl' or tag == 'dd':
		return content.strip() + "\n"
	
	return content


def parse_config(file_path, mapping):
	"""
	Parses the configuration file and handles 'include' recursion.
	Maps HTML command IDs to CSV Identifiers.
	"""
	if not os.path.exists(file_path):
		print(f"Warning: Config file {file_path} not found.")
		return

	with open(file_path, 'r') as f:
		for line in f:
			# Strip comments
			line = line.split('#')[0].strip()
			if not line:
				continue
			
			parts = line.split()
			cmd = parts[0]
			
			if cmd == 'include':
				if len(parts) > 1:
					parse_config(parts[1], mapping)
			elif cmd == 'page':
				if len(parts) > 2:
					# Map HTML_ID -> BASE_IDENTIFIER
					mapping[parts[1]] = parts[2]
			elif cmd == 'alias':
				# Ignore aliases.
				continue
			else:
				print(f"Warning: Unknown keyword '{cmd}' in config.")

def main():
	if len( sys.argv ) == 2:
		html_file = sys.argv[ 1 ]
	else:
		html_file = 'United_CCMDs_for_parse.html'

	config_file = 'manpages/manpages-wiki-autosync.cfg'
	csv_file = 'LANGUAGE.autosync.csv'

	# 1. Load Configuration
	# html_id -> base_id (e.g., 'error_fatal' -> 'ERRORFATAL')
	id_map = {}
	parse_config(config_file, id_map)
	
	if ( not id_map ):
		print( "Error: no mapping between command name and identifier." )
	
	# 2. Parse HTML
	if not os.path.exists(html_file):
		print("Error: HTML input file not found.")
		return

	with open(html_file, 'r') as f:
		soup = BeautifulSoup(f, 'html.parser')

	# extracted_data[base_id] = {'NAME': '...', 'DESC': '...'}
	extracted_data = {}
	seen_html_ids = set()

	# Find all spans with IDs - these are our command markers
	for span in soup.find_all('span', id=True):
		html_id = span['id']
		if html_id in seen_html_ids:
			print(f"Warning: Duplicate command definition in HTML: {html_id}")
			continue
		seen_html_ids.add(html_id)
		
		if html_id not in id_map:
			continue
		
		base_id = id_map[html_id]
		
		# Get command name (the parent <li> text)
		li_parent = span.find_parent('li')
		name_text = li_parent.get_text() if li_parent else ""
		
		# Get description (the next <dl> element)
		ul_parent = span.find_parent('ul')
		desc_text = ""
		if ul_parent:
			dl_sibling = ul_parent.find_next_sibling('dl')
			if dl_sibling:
				desc_text = format_node(dl_sibling).strip()
		
		extracted_data[base_id] = {
			'NAME': name_text,
			'DESC': desc_text
		}

	# 3. Read Existing CSV
	# csv_data[base_id] = {'NAME': [row], 'DESC': [row], 'EXMP': [row]}
	csv_data = {}
	header_rows = []
	
	if os.path.exists(csv_file):
		with open(csv_file, 'r', newline='') as f:
			reader = list(csv.reader(f))
			# Preserve headers
			header_rows = reader[:3]
			# Parse data rows
			for row in reader[3:]:
				if len(row) < 3: continue
				full_id = row[2] # Identifier column
				match = re.match(r'MANPAGES_(.*)_(NAME|DESC|EXMP)', full_id)
				if match:
					base_id = match.group(1)
					suffix = match.group(2)
					if base_id not in csv_data:
						csv_data[base_id] = {}
					csv_data[base_id][suffix] = row

	# 4. Merge Data
	for base_id, info in extracted_data.items():
		if base_id not in csv_data:
			# Create new entry if it doesn't exist in CSV
			csv_data[base_id] = {
				'NAME': ['', '', f'MANPAGES_{base_id}_NAME', '', ''],
				'DESC': ['', '', f'MANPAGES_{base_id}_DESC', '', ''],
				'EXMP': ['', '', f'MANPAGES_{base_id}_EXMP', '', '']
			}
		
		# Write/overwrite NAME:
		if csv_data[base_id]['NAME'][3] == "":
			print(f"New CCMD name 'MANPAGES_{base_id}_NAME'.")
		elif csv_data[base_id]['NAME'][3] != info['NAME']:
			print(f"Overwriting CCMD name 'MANPAGES_{base_id}_NAME'.")
		csv_data[base_id]['NAME'][3] = info['NAME']
		
		# Write/overwrite DESC:
		if csv_data[base_id]['DESC'][3] == "":
			print(f"New description 'MANPAGES_{base_id}_DESC'.")
		elif csv_data[base_id]['DESC'][3] != info['DESC']:
			print(f"Overwriting description 'MANPAGES_{base_id}_DESC'.")
		csv_data[base_id]['DESC'][3] = info['DESC']

	# 5. Write Sorted Output
	if not header_rows:
		header_rows = [
			['Identifier', 'Remark', 'Identifier', 'default', 'ru'],
			['(Column is unused)', 'Tabs size for this file: 4.', '', '', ''],
			['', '', '', '', '']
		]

	sorted_base_ids = sorted(csv_data.keys())
	
	with open(csv_file, 'w', newline = '') as f:
		writer = csv.writer(f, lineterminator = '\n')
		writer.writerows(header_rows)

		for b_id in sorted_base_ids:
			# Ensure every base_id has all 3 rows
			for suffix in ['NAME', 'DESC', 'EXMP']:
				row = csv_data[b_id].get(suffix)
				if not row:
					row = ['', '', f'MANPAGES_{b_id}_{suffix}', '', '']
				writer.writerow(row)


if __name__ == "__main__":
	main()
